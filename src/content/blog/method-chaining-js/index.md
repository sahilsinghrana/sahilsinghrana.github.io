---
author: "Sahil Rana"
image:
  url: "./titleImage.webp"
  alt: "llama3"
pubDate: 2024-07-01
title: Running LLM models in your local machine
description: "Learn how to run llama3, an LLM model, on your local machine using ollama."
slug: run-ai-models-locally
tags:
  [
    "AI",
    "ML",
    "llama",
    "LLM",
    "tokenizer",
    "ollama",
    "Sahil",
    "Rana",
  ]
---

# Running AI in our local machine

In this blog post, we will explore how to set up and run llama3, an advanced Large Language Model (LLM), on a Windows machine using ollama as our main tool.

## What is LLM?

LLM, or Large Language Model, refers to a class of AI models that can understand and generate human-like text. These models are used in various applications such as natural language processing and text generation.

[Learn more about LLM.](https://en.wikipedia.org/wiki/Large_language_model)

## What is ollama?

ollama is  a tool or framework for managing and running LLMs like llama3.

[Official Site](https://ollama.com/)

## Installing ollama

Before we can run llama3, we need to install ollama. Hereâ€™s how you can do it:

1. **Step 1:** Download the ollama installer from official website. [Link](https://ollama.com/download)
2. **Step 2:** Follow the installation instructions provided with the installer.

## Downloading llama3

Next, we need to download llama3, the LLM model we want to run locally:

```bash
ollama pull llama3
```

or


```bash
ollama run llama3
```


## Running llama3 using ollama

Once ollama and llama3 are installed, you can run llama3 with the following command:

```bash
ollama run llama3
```
Replace ollama run llama3 with the actual command provided by ollama to start llama3 on your machine.


## Asking amazing questions
